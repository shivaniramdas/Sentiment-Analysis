{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create fields for labels and text\n",
    "\n",
    "text_field = data.Field(tokenize = 'spacy')\n",
    "label_field = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the imdb dataset and split it into testing and training\n",
    "\n",
    "train_data, test_data = datasets.IMDB.splits(text_field, label_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 25000\n",
      "Test size: 25000\n"
     ]
    }
   ],
   "source": [
    "#check size of both\n",
    "print(f'Train size: {len(train_data)}')\n",
    "print(f'Test size: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Misfits',\n",
       "  'at',\n",
       "  'a',\n",
       "  'military',\n",
       "  'school',\n",
       "  '?',\n",
       "  'Hmmmm',\n",
       "  ',',\n",
       "  'sounds',\n",
       "  'funny',\n",
       "  ',',\n",
       "  'maybe',\n",
       "  'offensive',\n",
       "  'to',\n",
       "  'some',\n",
       "  '.',\n",
       "  'You',\n",
       "  'have',\n",
       "  'the',\n",
       "  'characters',\n",
       "  'there',\n",
       "  ',',\n",
       "  'the',\n",
       "  'Arab',\n",
       "  'thief',\n",
       "  ',',\n",
       "  'the',\n",
       "  'sex',\n",
       "  'crazy',\n",
       "  'teen',\n",
       "  ',',\n",
       "  'the',\n",
       "  'smart',\n",
       "  'mouth',\n",
       "  ',',\n",
       "  'the',\n",
       "  'pot',\n",
       "  'smoker',\n",
       "  ',',\n",
       "  'and',\n",
       "  'not',\n",
       "  'to',\n",
       "  'forget',\n",
       "  ',',\n",
       "  'the',\n",
       "  'guy',\n",
       "  'who',\n",
       "  'burns',\n",
       "  'things',\n",
       "  '.',\n",
       "  'Throw',\n",
       "  'in',\n",
       "  'a',\n",
       "  'strict',\n",
       "  'no',\n",
       "  'nonsense',\n",
       "  'Sergent',\n",
       "  ',',\n",
       "  'a',\n",
       "  'homosexual',\n",
       "  'Sergent',\n",
       "  'and',\n",
       "  'one',\n",
       "  'sexy',\n",
       "  'ammunition',\n",
       "  'teacher',\n",
       "  'and',\n",
       "  'it',\n",
       "  'makes',\n",
       "  'one',\n",
       "  'crazy',\n",
       "  'film',\n",
       "  'adventure.<br',\n",
       "  '/><br',\n",
       "  '/>I',\n",
       "  'have',\n",
       "  'seen',\n",
       "  'this',\n",
       "  'film',\n",
       "  'and',\n",
       "  'it',\n",
       "  'is',\n",
       "  'funny',\n",
       "  ',',\n",
       "  'because',\n",
       "  'the',\n",
       "  'comedy',\n",
       "  'is',\n",
       "  'revolved',\n",
       "  'around',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'if',\n",
       "  'you',\n",
       "  'try',\n",
       "  'to',\n",
       "  'work',\n",
       "  'together',\n",
       "  ',',\n",
       "  'things',\n",
       "  'get',\n",
       "  'done.<br',\n",
       "  '/><br',\n",
       "  '/>These',\n",
       "  'band',\n",
       "  'of',\n",
       "  'misfit',\n",
       "  'students',\n",
       "  'at',\n",
       "  'Weinberg',\n",
       "  'Military',\n",
       "  'school',\n",
       "  'have',\n",
       "  'been',\n",
       "  'placed',\n",
       "  'in',\n",
       "  'here',\n",
       "  'because',\n",
       "  ',',\n",
       "  'as',\n",
       "  'Sgt',\n",
       "  'Liceman',\n",
       "  'quotes',\n",
       "  '\"',\n",
       "  'because',\n",
       "  'you',\n",
       "  'are',\n",
       "  'outcasts',\n",
       "  ',',\n",
       "  'embarrassments',\n",
       "  'to',\n",
       "  'your',\n",
       "  'families',\n",
       "  'and',\n",
       "  'communities',\n",
       "  ',',\n",
       "  'disgraces',\n",
       "  '.',\n",
       "  '\"',\n",
       "  'One',\n",
       "  'of',\n",
       "  'Ralph',\n",
       "  'Macchio',\n",
       "  \"'s\",\n",
       "  'earlier',\n",
       "  'performances',\n",
       "  'before',\n",
       "  'the',\n",
       "  'Karate',\n",
       "  'Kid',\n",
       "  'and',\n",
       "  'My',\n",
       "  'Cousin',\n",
       "  'Vinny',\n",
       "  ',',\n",
       "  'with',\n",
       "  'appearances',\n",
       "  'from',\n",
       "  'Barbara',\n",
       "  'Bach',\n",
       "  'as',\n",
       "  'well',\n",
       "  ',',\n",
       "  'this',\n",
       "  'film',\n",
       "  'appeals',\n",
       "  'to',\n",
       "  'teens',\n",
       "  'and',\n",
       "  'young',\n",
       "  'adults.<br',\n",
       "  '/><br',\n",
       "  '/>Great',\n",
       "  'soundtrack',\n",
       "  'keeps',\n",
       "  'the',\n",
       "  'film',\n",
       "  'moving',\n",
       "  '.'],\n",
       " 'label': 'pos'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print an example\n",
    "vars(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 20000\n",
      "Validation size: 5000\n"
     ]
    }
   ],
   "source": [
    "#split train into train and validation and print size\n",
    "\n",
    "train_data, validation_data = train_data.split(split_ratio=0.8)\n",
    "\n",
    "print(f'Train size: {len(train_data)}')\n",
    "print(f'Validation size: {len(validation_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['This',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'storytelling',\n",
       "  'is',\n",
       "  'unacceptable',\n",
       "  'The',\n",
       "  'only',\n",
       "  'reason',\n",
       "  'this',\n",
       "  'film',\n",
       "  'is',\n",
       "  'anywhere',\n",
       "  'above',\n",
       "  'the',\n",
       "  '5',\n",
       "  'stars',\n",
       "  'out',\n",
       "  'of',\n",
       "  '10',\n",
       "  'line',\n",
       "  'is',\n",
       "  'because',\n",
       "  'it',\n",
       "  \"'s\",\n",
       "  'got',\n",
       "  'George',\n",
       "  'Lucas',\n",
       "  'behind',\n",
       "  'it',\n",
       "  ',',\n",
       "  'and',\n",
       "  'it',\n",
       "  'has',\n",
       "  'the',\n",
       "  'words',\n",
       "  '\"',\n",
       "  'Star',\n",
       "  '\"',\n",
       "  'and',\n",
       "  '\"',\n",
       "  'Wars',\n",
       "  '\"',\n",
       "  'in',\n",
       "  'its',\n",
       "  'title',\n",
       "  '.',\n",
       "  'That',\n",
       "  'is',\n",
       "  'an',\n",
       "  'insult',\n",
       "  'to',\n",
       "  'aspiring',\n",
       "  'filmmakers',\n",
       "  ',',\n",
       "  'and',\n",
       "  'many',\n",
       "  'others',\n",
       "  'out',\n",
       "  'there',\n",
       "  'who',\n",
       "  'have',\n",
       "  'made',\n",
       "  'clearly',\n",
       "  'superior',\n",
       "  'films',\n",
       "  'with',\n",
       "  'superior',\n",
       "  'story',\n",
       "  ',',\n",
       "  'writing',\n",
       "  'and',\n",
       "  'acting',\n",
       "  ',',\n",
       "  'but',\n",
       "  'did',\n",
       "  'not',\n",
       "  'get',\n",
       "  'the',\n",
       "  'credit',\n",
       "  '.',\n",
       "  'This',\n",
       "  'is',\n",
       "  'a',\n",
       "  'travesty.<br',\n",
       "  '/><br',\n",
       "  '/>First',\n",
       "  'things',\n",
       "  'first',\n",
       "  '.',\n",
       "  'The',\n",
       "  'story',\n",
       "  '.',\n",
       "  'Anakin',\n",
       "  \"'s\",\n",
       "  'evolution',\n",
       "  '?',\n",
       "  'There',\n",
       "  'is',\n",
       "  'none',\n",
       "  '.',\n",
       "  'Apart',\n",
       "  'from',\n",
       "  'a',\n",
       "  'little',\n",
       "  'make',\n",
       "  '-',\n",
       "  'up',\n",
       "  'around',\n",
       "  'the',\n",
       "  'eyes',\n",
       "  ',',\n",
       "  'and',\n",
       "  'a',\n",
       "  'little',\n",
       "  'yelling',\n",
       "  ',',\n",
       "  'there',\n",
       "  'is',\n",
       "  'none',\n",
       "  '.',\n",
       "  'He',\n",
       "  'becomes',\n",
       "  'young',\n",
       "  ',',\n",
       "  'stupid',\n",
       "  ',',\n",
       "  'cocky',\n",
       "  'Anakin',\n",
       "  'Skywalker',\n",
       "  'to',\n",
       "  'Darth',\n",
       "  'Vader',\n",
       "  'in',\n",
       "  'a',\n",
       "  'single',\n",
       "  'blow',\n",
       "  '.',\n",
       "  'The',\n",
       "  'only',\n",
       "  'thing',\n",
       "  'consistent',\n",
       "  'about',\n",
       "  'Darth',\n",
       "  'Vader',\n",
       "  'in',\n",
       "  'the',\n",
       "  'original',\n",
       "  'series',\n",
       "  'was',\n",
       "  'his',\n",
       "  'intelligence',\n",
       "  ',',\n",
       "  'how',\n",
       "  'good',\n",
       "  'he',\n",
       "  'was',\n",
       "  'at',\n",
       "  'almost',\n",
       "  'everything',\n",
       "  'he',\n",
       "  'did',\n",
       "  ',',\n",
       "  'planning',\n",
       "  ',',\n",
       "  'fighting',\n",
       "  ',',\n",
       "  'you',\n",
       "  'name',\n",
       "  'it',\n",
       "  '.',\n",
       "  'The',\n",
       "  'only',\n",
       "  'consistent',\n",
       "  'thing',\n",
       "  'about',\n",
       "  'Anakin',\n",
       "  'that',\n",
       "  'is',\n",
       "  'perceived',\n",
       "  'in',\n",
       "  'the',\n",
       "  'prequel',\n",
       "  'trilogy',\n",
       "  'is',\n",
       "  'his',\n",
       "  'consistent',\n",
       "  'stupidity',\n",
       "  '.',\n",
       "  'He',\n",
       "  'even',\n",
       "  'loses',\n",
       "  'his',\n",
       "  'body',\n",
       "  'because',\n",
       "  'of',\n",
       "  'a',\n",
       "  'bout',\n",
       "  'of',\n",
       "  'stupid',\n",
       "  'cockiness.<br',\n",
       "  '/><br',\n",
       "  '/>What',\n",
       "  'part',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Emperor',\n",
       "  'Palpatine',\n",
       "  'telling',\n",
       "  'him',\n",
       "  'legends',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Sith',\n",
       "  'does',\n",
       "  'not',\n",
       "  'point',\n",
       "  'to',\n",
       "  'the',\n",
       "  'Emperor',\n",
       "  'being',\n",
       "  'a',\n",
       "  'Sith',\n",
       "  '?',\n",
       "  'Unacceptable!<br',\n",
       "  '/><br',\n",
       "  '/>The',\n",
       "  'fight',\n",
       "  'scenes',\n",
       "  'used',\n",
       "  'too',\n",
       "  'many',\n",
       "  'digital',\n",
       "  'doubles',\n",
       "  '.',\n",
       "  'Everyone',\n",
       "  \"'s\",\n",
       "  'flying',\n",
       "  'all',\n",
       "  'over',\n",
       "  'the',\n",
       "  'place',\n",
       "  'like',\n",
       "  'teddy',\n",
       "  'bears',\n",
       "  'in',\n",
       "  'a',\n",
       "  'make',\n",
       "  '-',\n",
       "  'believe',\n",
       "  'doll',\n",
       "  'house',\n",
       "  '.',\n",
       "  'Count',\n",
       "  'Dooku',\n",
       "  ',',\n",
       "  'Emperor',\n",
       "  'Palpatine',\n",
       "  ',',\n",
       "  'Anakin',\n",
       "  ',',\n",
       "  'Obi',\n",
       "  '-',\n",
       "  'Wan',\n",
       "  ',',\n",
       "  'almost',\n",
       "  'every',\n",
       "  'fighter',\n",
       "  'had',\n",
       "  'a',\n",
       "  'rubbery',\n",
       "  'digital',\n",
       "  'double',\n",
       "  'jumping',\n",
       "  'around.<br',\n",
       "  '/><br',\n",
       "  '/>In',\n",
       "  'one',\n",
       "  'specific',\n",
       "  'fight',\n",
       "  'scene',\n",
       "  ',',\n",
       "  'Obi',\n",
       "  '-',\n",
       "  'Wan',\n",
       "  'and',\n",
       "  'Anakin',\n",
       "  'in',\n",
       "  'the',\n",
       "  'climactic',\n",
       "  'battle',\n",
       "  ',',\n",
       "  'they',\n",
       "  'both',\n",
       "  'actually',\n",
       "  'stop',\n",
       "  'in',\n",
       "  'the',\n",
       "  'middle',\n",
       "  'of',\n",
       "  'parries',\n",
       "  'and',\n",
       "  'ripostes',\n",
       "  ',',\n",
       "  'to',\n",
       "  'twirl',\n",
       "  'their',\n",
       "  'sabers',\n",
       "  'a',\n",
       "  'few',\n",
       "  'times',\n",
       "  'while',\n",
       "  'inches',\n",
       "  'apart',\n",
       "  '.',\n",
       "  'I',\n",
       "  'realize',\n",
       "  'the',\n",
       "  'fights',\n",
       "  'are',\n",
       "  'choreographed',\n",
       "  ',',\n",
       "  'but',\n",
       "  'that',\n",
       "  'just',\n",
       "  'got',\n",
       "  'me',\n",
       "  'shaking',\n",
       "  'my',\n",
       "  'head',\n",
       "  'in',\n",
       "  'disbelief',\n",
       "  'and',\n",
       "  'disgust.<br',\n",
       "  '/><br',\n",
       "  '/>The',\n",
       "  'writing',\n",
       "  'was',\n",
       "  'awful',\n",
       "  '.',\n",
       "  'All',\n",
       "  'the',\n",
       "  'dialogue',\n",
       "  'was',\n",
       "  'of',\n",
       "  'tremendously',\n",
       "  'low',\n",
       "  'quality',\n",
       "  '.',\n",
       "  'The',\n",
       "  'good',\n",
       "  'actors',\n",
       "  'like',\n",
       "  'Ewan',\n",
       "  'McGregor',\n",
       "  'and',\n",
       "  'Natalie',\n",
       "  'Portman',\n",
       "  'did',\n",
       "  'the',\n",
       "  'best',\n",
       "  'they',\n",
       "  'could',\n",
       "  'with',\n",
       "  'their',\n",
       "  'lines',\n",
       "  ',',\n",
       "  'but',\n",
       "  'that',\n",
       "  'just',\n",
       "  'was',\n",
       "  \"n't\",\n",
       "  'enough',\n",
       "  '.',\n",
       "  'I',\n",
       "  'ca',\n",
       "  \"n't\",\n",
       "  'say',\n",
       "  'enough',\n",
       "  'bad',\n",
       "  'things',\n",
       "  'about',\n",
       "  'this',\n",
       "  'film',\n",
       "  '.',\n",
       "  'Too',\n",
       "  'much',\n",
       "  'special',\n",
       "  'effects',\n",
       "  ',',\n",
       "  'plot',\n",
       "  'holes',\n",
       "  'bigger',\n",
       "  'than',\n",
       "  'the',\n",
       "  'centre',\n",
       "  'of',\n",
       "  'the',\n",
       "  'universe',\n",
       "  ',',\n",
       "  'and',\n",
       "  'absolutely',\n",
       "  'no',\n",
       "  'insights',\n",
       "  'into',\n",
       "  'any',\n",
       "  'of',\n",
       "  'the',\n",
       "  'characters',\n",
       "  '.',\n",
       "  'This',\n",
       "  'is',\n",
       "  'the',\n",
       "  'biggest',\n",
       "  'mistake',\n",
       "  'of',\n",
       "  'this',\n",
       "  'film',\n",
       "  ':',\n",
       "  'nothing',\n",
       "  'new',\n",
       "  'is',\n",
       "  'offered',\n",
       "  '.',\n",
       "  'We',\n",
       "  'know',\n",
       "  'the',\n",
       "  'rough',\n",
       "  'picture',\n",
       "  'of',\n",
       "  'everything',\n",
       "  ',',\n",
       "  'all',\n",
       "  'Lucas',\n",
       "  'did',\n",
       "  'was',\n",
       "  'colour',\n",
       "  'it',\n",
       "  'in.<br',\n",
       "  '/><br',\n",
       "  '/>We',\n",
       "  'knew',\n",
       "  'Anakin',\n",
       "  'lost',\n",
       "  'his',\n",
       "  'limbs',\n",
       "  '.',\n",
       "  'We',\n",
       "  'knew',\n",
       "  'Luke',\n",
       "  'and',\n",
       "  'Leia',\n",
       "  'are',\n",
       "  'brother',\n",
       "  'and',\n",
       "  'sister',\n",
       "  ',',\n",
       "  'we',\n",
       "  'knew',\n",
       "  'Luke',\n",
       "  'is',\n",
       "  'Anakin',\n",
       "  \"'s\",\n",
       "  'son',\n",
       "  ',',\n",
       "  'we',\n",
       "  'knew',\n",
       "  'Obi',\n",
       "  '-',\n",
       "  'Wan',\n",
       "  'and',\n",
       "  'Yoda',\n",
       "  'go',\n",
       "  'to',\n",
       "  'exile',\n",
       "  ',',\n",
       "  'we',\n",
       "  'knew',\n",
       "  'everything',\n",
       "  '.',\n",
       "  'Nothing',\n",
       "  'new',\n",
       "  'is',\n",
       "  'offered',\n",
       "  'in',\n",
       "  'this',\n",
       "  'film',\n",
       "  '.',\n",
       "  'If',\n",
       "  'that',\n",
       "  \"'s\",\n",
       "  'all',\n",
       "  'the',\n",
       "  'fans',\n",
       "  'wanted',\n",
       "  ',',\n",
       "  'then',\n",
       "  'that',\n",
       "  \"'s\",\n",
       "  'fine',\n",
       "  ',',\n",
       "  'Lucas',\n",
       "  'could',\n",
       "  \"n't\",\n",
       "  'have',\n",
       "  'gone',\n",
       "  'wrong.<br',\n",
       "  '/><br',\n",
       "  '/>But',\n",
       "  'when',\n",
       "  'Anakin',\n",
       "  'finally',\n",
       "  'becomes',\n",
       "  'Darth',\n",
       "  'Vader',\n",
       "  ',',\n",
       "  'and',\n",
       "  'he',\n",
       "  'asks',\n",
       "  'after',\n",
       "  'Padme',\n",
       "  ',',\n",
       "  'and',\n",
       "  'hears',\n",
       "  'she',\n",
       "  'is',\n",
       "  'dead',\n",
       "  ',',\n",
       "  'he',\n",
       "  'reaches',\n",
       "  'out',\n",
       "  'his',\n",
       "  'arms',\n",
       "  'awkwardly',\n",
       "  'and',\n",
       "  'screams',\n",
       "  '\"',\n",
       "  'Nooooooooooooooooooooo',\n",
       "  '.',\n",
       "  '\"',\n",
       "  'That',\n",
       "  'scene',\n",
       "  'screamed',\n",
       "  'B',\n",
       "  '-',\n",
       "  'movie',\n",
       "  'all',\n",
       "  'the',\n",
       "  'way',\n",
       "  ',',\n",
       "  'and',\n",
       "  'I',\n",
       "  'was',\n",
       "  'half',\n",
       "  'expecting',\n",
       "  'Darth',\n",
       "  'Vader',\n",
       "  'to',\n",
       "  'go',\n",
       "  '\"',\n",
       "  'DANGER',\n",
       "  'WILL',\n",
       "  'ROBINSON',\n",
       "  ',',\n",
       "  'DANGER',\n",
       "  '\"',\n",
       "  'at',\n",
       "  'any',\n",
       "  'time',\n",
       "  '.',\n",
       "  'That',\n",
       "  'is',\n",
       "  'what',\n",
       "  'this',\n",
       "  'is',\n",
       "  '.',\n",
       "  'A',\n",
       "  'B',\n",
       "  '-',\n",
       "  'movie',\n",
       "  ',',\n",
       "  'disguised',\n",
       "  'by',\n",
       "  'a',\n",
       "  'huge',\n",
       "  'budget',\n",
       "  'and',\n",
       "  'a',\n",
       "  'ultra',\n",
       "  '-',\n",
       "  'loyalist',\n",
       "  'fan',\n",
       "  'base',\n",
       "  'that',\n",
       "  'will',\n",
       "  'settle',\n",
       "  'with',\n",
       "  'anything',\n",
       "  'now',\n",
       "  'that',\n",
       "  'the',\n",
       "  'first',\n",
       "  'two',\n",
       "  'movies',\n",
       "  'have',\n",
       "  'pulled',\n",
       "  'their',\n",
       "  'standards',\n",
       "  'down',\n",
       "  'to',\n",
       "  'the',\n",
       "  'pits',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Earth',\n",
       "  '.'],\n",
       " 'label': 'neg'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use glove pretrained embeddings\n",
    "#use only top 25000 most commonly occurring words\n",
    "text_field.build_vocab(train_data, max_size=25000, vectors=\"glove.6B.100d\")\n",
    "label_field.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25002"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many tokens are there\n",
    "len(text_field.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 230828),\n",
       " (',', 219882),\n",
       " ('.', 188816),\n",
       " ('and', 124865),\n",
       " ('a', 124835),\n",
       " ('of', 114902),\n",
       " ('to', 106683),\n",
       " ('is', 86951),\n",
       " ('in', 69989),\n",
       " ('I', 62012),\n",
       " ('it', 61133),\n",
       " ('that', 55926),\n",
       " ('\"', 50642),\n",
       " (\"'s\", 49451),\n",
       " ('this', 48361),\n",
       " ('-', 41827),\n",
       " ('/><br', 40423),\n",
       " ('was', 39758),\n",
       " ('as', 34788),\n",
       " ('with', 34209),\n",
       " ('movie', 33840),\n",
       " ('for', 33370),\n",
       " ('film', 31061),\n",
       " ('The', 29999),\n",
       " ('but', 27973)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#25 most common\n",
    "text_field.vocab.freqs.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 128\n",
    "#create iterators for train, test and validation sets\n",
    "\n",
    "train_iter, validation_iter, test_iter = data.BucketIterator.splits((train_data, validation_data, test_data), batch_size=batch, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   66,   378,     0,  ...,    11,   378,  7466],\n",
      "        [ 5963,     6, 13033,  ...,   141,   173,  2774],\n",
      "        [  241,   361,    52,  ...,  4736,   288,     9],\n",
      "        ...,\n",
      "        [    1,     1,     1,  ...,     1,     1,     1],\n",
      "        [    1,     1,     1,  ...,     1,     1,     1],\n",
      "        [    1,     1,     1,  ...,     1,     1,     1]], device='cuda:0')\n",
      "972 128\n",
      "Plot : an amorous couple decide to engage in some extra - marital hijinks in a flashy car . They then become stuck ( literally ) in a <unk> <unk> , while said car wanders aimlessly about the countryside until the hapless couple are rescued by the <unk> /><br />That 's it . That 's the entire movie . There may have been some dialogue here and there , but nothing comes to mind . It should be obvious by now that this movie is not just pointless , but actually physically painful to watch . The fact that it starred two of the <unk> best up - and - coming actors ( one of whom is now sadly deceased ) only adds to the horror.<br /><br <unk> <unk> was outstanding in the very much deserved Oscar - winning ' <unk> of Fire ' . Let 's remember him for that role , and try hard to pretend that this particular <unk> abomination never happened . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> ------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for b in train_iter:\n",
    "    print(b.text)\n",
    "    r,c = b.text.size()\n",
    "    print(r,c)\n",
    "    for i in range(r):\n",
    "        print(text_field.vocab.itos[b.text[i][120]], end=\" \")\n",
    "    print(\"------------------------\\n\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#architecture of network:\n",
    "# embedding layer -> n x Conv Layers -> max pooling -> dropout -> fc layer\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class cnn(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, n_filters, filter_sizes, output_dim, dropout):\n",
    "        super(cnn, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        \n",
    "        self.filters = nn.ModuleList([nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(fs, emb_dim)) \n",
    "                                      for fs in filter_sizes])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(n_filters*len(filter_sizes), output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x: (word, batch)\n",
    "        #conv2d wants batch as first dimension, so we switch x dims\n",
    "        x = x.transpose(0,1)\n",
    "        #x: (batch, word)\n",
    "        x_emb = self.embedding(x).unsqueeze(1)\n",
    "        #x_emb: batch, 1, word, emb_dim\n",
    "        x_conv = [filt(x_emb) for filt in self.filters]\n",
    "        #x_conv[0]: batch, n_filters, word, 1\n",
    "        x_conv_relu = [F.relu(t).squeeze(3) for t in x_conv]\n",
    "        #x_conv_relu[0] = batch, n_filters, word\n",
    "        x_maxpool = [F.max_pool1d(input=t, kernel_size=t.size(2)).squeeze(2) for t in x_conv_relu]\n",
    "        #x_maxpool[0] = batch, n_filters\n",
    "        x_concat = torch.cat(x_maxpool, dim=1)\n",
    "        #x_concat= batch, n_filter*n_filter\n",
    "        x_drop = self.dropout(x_concat)\n",
    "        return self.fc(x_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.4\n",
    "output_dim = 1\n",
    "filters = [3,4,5]\n",
    "n_filters = 100\n",
    "emb_dim = 100\n",
    "input_dim = len(text_field.vocab)\n",
    "\n",
    "model = cnn(input_dim, emb_dim, n_filters, filters, output_dim, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [-0.1986,  0.3232,  0.7498,  ..., -0.4724,  0.8580,  0.4183],\n",
       "        [-0.0482,  0.3399,  0.0066,  ...,  0.0626,  0.4746,  0.9363],\n",
       "        [-0.0601, -0.1312, -0.0897,  ..., -0.4999,  0.9753,  0.5777]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_vect = text_field.vocab.vectors\n",
    "#copy into model\n",
    "model.embedding.weight.data.copy_(pretrained_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define accuracy\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    y_pred = torch.round(torch.sigmoid(y_pred))\n",
    "    correct = (y_pred==y_true).float()\n",
    "    return sum(correct)/len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define optimizer\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "lossfunc = nn.BCEWithLogitsLoss().to(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, lossfunction):\n",
    "    \n",
    "    loss = 0.\n",
    "    acc = 0.\n",
    "    model.train()\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(batch.text).squeeze(1)\n",
    "        batch_loss = lossfunction(y_pred, batch.label)\n",
    "        batch_acc = accuracy_score(batch.label, y_pred)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        loss += batch_loss.item()\n",
    "        acc += batch_acc.item()\n",
    "        \n",
    "        if i>0 and i%20==0:\n",
    "            print('Train batch', i, 'done.')\n",
    "    return loss/len(iterator), acc/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, lossfunction):\n",
    "    \n",
    "    loss = 0.\n",
    "    acc = 0.\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            y_pred = model(batch.text).squeeze(1)\n",
    "            batch_loss = lossfunction(y_pred, batch.label)\n",
    "            batch_acc = accuracy_score(batch.label, y_pred)\n",
    "            \n",
    "            loss += batch_loss.item()\n",
    "            acc += batch_acc.item()\n",
    "            \n",
    "            if i>0 and i%20==0:\n",
    "                print('Evaluate batch', i, 'done')\n",
    "    return loss/len(iterator), acc/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch 20 done.\n",
      "Train batch 40 done.\n",
      "Train batch 60 done.\n",
      "Train batch 80 done.\n",
      "Train batch 100 done.\n",
      "Train batch 120 done.\n",
      "Train batch 140 done.\n",
      "Evaluate batch 20 done\n",
      "Epoch: 0\n",
      "Training stats:\n",
      " Accuracy: 0.733031449044586 ,Loss: 0.5203975380226306\n",
      "Validation stats:\n",
      " Accuracy: 0.830859375 ,Loss: 0.3836495392024517\n",
      "Train batch 20 done.\n",
      "Train batch 40 done.\n",
      "Train batch 60 done.\n",
      "Train batch 80 done.\n",
      "Train batch 100 done.\n",
      "Train batch 120 done.\n",
      "Train batch 140 done.\n",
      "Evaluate batch 20 done\n",
      "Epoch: 1\n",
      "Training stats:\n",
      " Accuracy: 0.8682324840764332 ,Loss: 0.315547597730995\n",
      "Validation stats:\n",
      " Accuracy: 0.8759765625 ,Loss: 0.29109086766839026\n",
      "Train batch 20 done.\n",
      "Train batch 40 done.\n",
      "Train batch 60 done.\n",
      "Train batch 80 done.\n",
      "Train batch 100 done.\n",
      "Train batch 120 done.\n",
      "Train batch 140 done.\n",
      "Evaluate batch 20 done\n",
      "Epoch: 2\n",
      "Training stats:\n",
      " Accuracy: 0.9106787420382165 ,Loss: 0.2325771002063326\n",
      "Validation stats:\n",
      " Accuracy: 0.88984375 ,Loss: 0.26478078290820123\n",
      "Train batch 20 done.\n",
      "Train batch 40 done.\n",
      "Train batch 60 done.\n",
      "Train batch 80 done.\n",
      "Train batch 100 done.\n",
      "Train batch 120 done.\n",
      "Train batch 140 done.\n",
      "Evaluate batch 20 done\n",
      "Epoch: 3\n",
      "Training stats:\n",
      " Accuracy: 0.9381468949044586 ,Loss: 0.1684077036133997\n",
      "Validation stats:\n",
      " Accuracy: 0.89140625 ,Loss: 0.25310142189264295\n",
      "Train batch 20 done.\n",
      "Train batch 40 done.\n",
      "Train batch 60 done.\n",
      "Train batch 80 done.\n",
      "Train batch 100 done.\n",
      "Train batch 120 done.\n",
      "Train batch 140 done.\n",
      "Evaluate batch 20 done\n",
      "Epoch: 4\n",
      "Training stats:\n",
      " Accuracy: 0.9630274681528662 ,Loss: 0.11481281768554336\n",
      "Validation stats:\n",
      " Accuracy: 0.8935546875 ,Loss: 0.2631428994238377\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iter, optimizer, lossfunc)\n",
    "    valid_loss, valid_acc = evaluate(model, validation_iter, lossfunc)\n",
    "    \n",
    "    print('Epoch:', epoch)\n",
    "    print('Training stats:\\n Accuracy:', train_acc, ',Loss:', train_loss)\n",
    "    print('Validation stats:\\n Accuracy:', valid_acc, ',Loss:', valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate batch 20 done\n",
      "Evaluate batch 40 done\n",
      "Evaluate batch 60 done\n",
      "Evaluate batch 80 done\n",
      "Evaluate batch 100 done\n",
      "Evaluate batch 120 done\n",
      "Evaluate batch 140 done\n",
      "Evaluate batch 160 done\n",
      "Evaluate batch 180 done\n",
      "Test accuracy: 0.8861208545918368\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "_, test_acc = evaluate(model, test_iter, lossfunc)\n",
    "print('Test accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
